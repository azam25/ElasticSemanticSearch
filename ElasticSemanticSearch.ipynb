{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c76866-6f03-4421-8be7-a2d6c3682480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers\n",
    "# !pip install \"elasticsearch>=8.0.0,<9.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6a79a-041a-427f-b77f-3b74bd51bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Optional\n",
    "from elasticsearch import Elasticsearch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "class HybridPDFSearch:\n",
    "    def __init__(self, \n",
    "                 index_name: str = \"hybrid_pdf\",\n",
    "                 embedding_model: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.es = Elasticsearch(\n",
    "                                \"https://localhost:9200\",\n",
    "                                basic_auth=(\"elastic\", \"Ra1MKkShNaQmNmlZX5uv\"),\n",
    "                                verify_certs=False)\n",
    "        self.index_name = index_name\n",
    "        self.model = SentenceTransformer(embedding_model)\n",
    "        self.vector_dim = self.model.get_sentence_embedding_dimension()\n",
    "        self._ensure_index()\n",
    "\n",
    "    def _ensure_index(self):\n",
    "        mapping = {\n",
    "            \"mappings\": {\n",
    "                \"properties\": {\n",
    "                    \"content\": {\"type\": \"text\"},\n",
    "                    \"content_vector\": {\"type\": \"dense_vector\", \"dims\": self.vector_dim}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        if self.es.indices.exists(index=self.index_name):\n",
    "            pass  # Keep existing index\n",
    "        else:\n",
    "            self.es.indices.create(index=self.index_name, body=mapping)\n",
    "\n",
    "    def _extract_text_from_pdf(self, pdf_path: str) -> List[str]:\n",
    "        \"\"\"Extract text per page (or as chunks if desired)\"\"\"\n",
    "        if not os.path.exists(pdf_path):\n",
    "            raise FileNotFoundError(f\"{pdf_path} not found\")\n",
    "        reader = PdfReader(pdf_path)\n",
    "        # Optionally, split into paragraphs, pages, etc.\n",
    "        pages = [page.extract_text() for page in reader.pages]\n",
    "        # Filter out None/empty pages\n",
    "        return [txt.strip() for txt in pages if txt and txt.strip()]\n",
    "\n",
    "    def index_pdf(self, pdf_path: str):\n",
    "        \"\"\"Extracts and indexes the PDF text as separate documents per page.\"\"\"\n",
    "        texts = self._extract_text_from_pdf(pdf_path)\n",
    "        for idx, text in enumerate(texts):\n",
    "            vector = self.model.encode(text).tolist()\n",
    "            doc_id = f\"{os.path.basename(pdf_path)}_page_{idx}\"\n",
    "            self.es.index(index=self.index_name, id=doc_id, body={\n",
    "                \"content\": text,\n",
    "                \"content_vector\": vector\n",
    "            })\n",
    "\n",
    "    def search(self, query: str, top_k: int = 5) -> List[dict]:\n",
    "        \"\"\"Hybrid search: BM25 (keyword) + cosine similarity\"\"\"\n",
    "        query_vector = self.model.encode(query).tolist()\n",
    "        body = {\n",
    "            \"size\": top_k,\n",
    "            \"query\": {\n",
    "                \"script_score\": {\n",
    "                    \"query\": {\n",
    "                        \"match\": {\"content\": {\"query\": query}}\n",
    "                    },\n",
    "                    \"script\": {\n",
    "                        \"source\": \"cosineSimilarity(params.query_vector, 'content_vector') + 1.0\",\n",
    "                        \"params\": {\"query_vector\": query_vector}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        results = self.es.search(index=self.index_name, body=body)\n",
    "        return [\n",
    "            {\"score\": hit[\"_score\"], \"content\": hit[\"_source\"][\"content\"]}\n",
    "            for hit in results[\"hits\"][\"hits\"]\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c7977-4453-4ad7-be17-b5ee8e5ec098",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# === INPUT FILE and INITIALIZATION ===\n",
    "pdf_path = \"InputData/the-state-of-ai-in-2023-generative-ais-breakout-year_vf.pdf\"\n",
    "searcher = HybridPDFSearch()\n",
    "searcher.index_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c2497a-77c1-4efa-960a-ac2bea78a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now search for any query\n",
    "query = \"Tell me potential risks of generative AI adoption in enterprise.\"\n",
    "results = searcher.search(query, top_k=3)\n",
    "for idx, res in enumerate(results, 1):\n",
    "    print(f\"{idx}. [Score: {res['score']:.2f}]\\n{res['content']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1013ad-ee00-4336-9720-61a27ae8624e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241cb18-69aa-4b10-b600-13eb25f4a244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
